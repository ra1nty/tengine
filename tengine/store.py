import warnings
import configparser
import itertools
from pathlib import Path
from collections import defaultdict
import pandas as pd
from tqdm import tqdm
from tengine.utils import df_column_filter, find_min_freq


class Store(object):
    def __init__(self, config_file='engine.ini', auto_update=True, force_download=False, filter_warnings=True) -> None:
        """Initialize the Store

        Args:
            config_file (str, optional): The config file. Defaults to 'engine.ini'.
            auto_update (bool, optional): Whether to perform auto-updating on-initializing. Defaults to True.
            force_download (bool, optional): If set to True, will delete all existing series and download. Defaults to False.
            filter_warnings (bool, optional): Filter the NatualNameWarning generated by PyTables. Defaults to True.
        """
        if filter_warnings:
            from tables import NaturalNameWarning
            warnings.filterwarnings("ignore", category=NaturalNameWarning)
        pd.set_option('io.hdf.default_format','table')
        self.config = configparser.ConfigParser()
        self.config.read(config_file)
        self.daemon = {}
        self.__load_modules()
        self.mapping: pd.DataFrame = pd.read_csv(self.config['store']['mapping_file'], header=0, dtype=object)
        self.mapping.set_index('custom_name', inplace=True)
        self.store = pd.HDFStore(self.config['store']['storage_file'])
        if force_download:
            for source in self.daemon.keys():
                try:
                    self.store.remove("/"+source)
                except KeyError:
                    pass
            self.update()
        elif auto_update:
            self.update()

    def __load_modules(self) -> None:
        """Load modules
        """
        modulestr = self.config['store'].get('enable_plugin')
        if modulestr is None:
            warnings.warn("No module loaded, download/update will be disabled", UserWarning)
            return
        modules = [module.strip() for module in modulestr.split(',')]
        from tengine.plugins import load_plugin
        for module in modules:
            self.daemon[module] = load_plugin(module, **self.config[module])

    def update(self) -> None:
        """Perform updating, all series defined in mapping but not in datastore will be downloaded.
        Existing series will be check for update 
        """        
        if not self.daemon:
            warnings.warn("No module loaded, download/update are disabled", UserWarning)
            return
        keys = self.store.keys()
        download_queue, update_queue = defaultdict(list), defaultdict(list)
        for source, ticker in set(zip(self.mapping.source, self.mapping.ticker)):
            key = self.create_key(source, ticker)
            if key not in keys:
                download_queue[source].append(ticker)
            else:
                update_queue[source].append(ticker)
        for source in download_queue.keys():
            if source in self.daemon:
                if self.daemon[source].BULK_DOWNLOAD:
                    print("Bulk downloading data from {}".format(source))
                    self.download_series_bulk(source, download_queue[source])
                else:
                    tickers = tqdm(download_queue[source])
                    for ticker in tickers:
                        tickers.set_description("Downloading {} from {}".format(ticker, source))
                        self.download_series(source, ticker)
            else:
                warnings.warn("No module loaded for source {}, Series {} not downloaded".format(source, ','.join(download_queue[source])), UserWarning)
        for source in update_queue.keys():
            if source in self.daemon:
                if self.daemon[source].BULK_DOWNLOAD:
                    print("Bulk downloading data from {}".format(source))
                    self.download_series_bulk(source, update_queue[source])
                else:
                    tickers = tqdm(update_queue[source])
                    for ticker in tickers:
                        tickers.set_description("Updating {} from {}".format(ticker, source))
                        self.download_series(source, ticker)
            else:
                warnings.warn("No module loaded for source {}, Series {} not downloaded".format(source, ','.join(download_queue[source])), UserWarning)

                
    def download_series(self, source: str, ticker: str, start=None, end=None, save=True) -> pd.Series: 
        series, meta_info = self.daemon[source].download_series(ticker, start, end)
        if save:
            key = self.create_key(source, ticker)
            self.store.append(key, series)
            if not meta_info.empty and source == 'fred':
                self.store.append(key+'/meta', meta_info)
        return series
    
    def download_series_bulk(self, source, tickers, start=None, end=None, save=True):
        raise NotImplementedError
    
    def get_mapping_by_name(self, name) -> pd.DataFrame:
        if pd.api.types.is_list_like(name):
            return self.mapping.loc[name]
        else:
            return self.mapping.loc[[name]]

    def get_mapping_by_ticker(self, ticker) -> pd.DataFrame:
        if pd.api.types.is_list_like(ticker):
            return self.mapping.loc[self.mapping.ticker.isin(ticker)]
        else:
            return self.mapping.loc[self.mapping.ticker == ticker]

    def get_meta_info(self, names, use_custom=False) -> dict:
        universe = None
        if names is not None and use_custom:
            universe = self.get_mapping_by_name(names)
        if names is not None and not use_custom:
            universe = self.get_mapping_by_ticker(names)
        if universe is None or universe.empty:
            raise ValueError("No Input / No series match your criteria")
        tickers, sources = universe.ticker,  universe.source
        ret = {}
        for t, s in zip(tickers, sources):
            key = self.create_key(s, t) + '/meta'
            meta_df = self.store.select(key)
            ret[t] = meta_df
        return ret

    def get_series(self, names=None, use_custom=True, freq='M', start=None, end=None, **kwargs) -> pd.DataFrame:
        universe = None
        if names is not None and use_custom:
            universe = self.get_mapping_by_name(names)
        if names is not None and not use_custom:
            universe = self.get_mapping_by_ticker(names)
        if kwargs:
            universe = df_column_filter(universe, **kwargs) if universe is not None else df_column_filter(self.mapping, **kwargs)
        if universe is None or universe.empty:
            raise ValueError("No Input / No series match your criteria")
        tickers, sources, freqs = universe.ticker,  universe.source, None
        tickers = tickers if pd.api.types.is_list_like(tickers) else [tickers]
        sources = sources if pd.api.types.is_list_like(sources) else [sources]
        if pd.api.types.is_list_like(freq):
            if len(freq) == len(tickers) or len(tickers) == 1:
                freqs = freq
            else:
                raise ValueError("Frequencies and names not aligned")
        else:
            freqs = [freq for _ in range(len(tickers))]
        seriess = []
        start, end, query_str = self.create_index_query(start, end)
        dpoints = [start] if start is not None else []
        if end is not None:
            dpoints += [end]
        for ts, f in zip(itertools.cycle(zip(tickers, sources)), freqs):
            t, s = ts
            key = self.create_key(s, t)
            try:
                series_raw = self.store.select(key, query_str)
            except KeyError:
                raise KeyError("No available data for {} at frequency {} from {}".format(t, f, s))
            series_raw = series_raw.resample(f).last().to_period(f).to_timestamp(how='e')
            seriess.append(series_raw)
            dpoints += [series_raw.index[0], series_raw.index[-1]]
        idx = pd.period_range(start=min(dpoints), end=max(dpoints), freq=find_min_freq(freqs)).to_timestamp(how='e')
        for series_raw in seriess:
            series_raw.reindex(idx)
        return pd.concat(seriess, axis=1)
    
    @staticmethod
    def create_key(source: str, ticker: str) -> str:
        return (source+'/'+ticker).replace(' ', '_')
    
    @staticmethod
    def create_index_query(start, end):
        query_str = None
        if start is not None and end is not None:
            start, end = pd.Timestamp(start).to_period('D').to_timestamp(how='e'), pd.Timestamp(end).to_period('D').to_timestamp(how='e')
            query_str = 'index <= end & index >= start'
        elif start is not None:
            start = pd.Timestamp(start)
            query_str = 'index >= start'
        elif end is not None:
            end = pd.Timestamp(end)
            query_str = 'index <= end'
        return start, end, query_str

    def __getitem__(self, series_name):
        return self.get_series(series_name)

    def __enter__(self):
        return self
    
    def close(self):
        self.store.close()
    
    def __exit__(self, exc_type, exc_value, traceback):
        self.close()
