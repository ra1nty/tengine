from typing import List, Tuple
import warnings
from collections import defaultdict
import pandas as pd
from tqdm import tqdm
from tengine.core import TimeSeries
from tengine.logging import get_logger, raise_if, raise_log, raise_if_not
from tengine.io.rootstore import ReadWriteStore


logger = get_logger(__name__)


class HDFStore(ReadWriteStore):
    def __init__(self, config_file='store.ini', auto_update=True, force_download=False, filter_warnings=True) -> None:
        """Initialize the Store

        Args:
            config_file (str, optional): The config file. Defaults to 'store.ini'.
            auto_update (bool, optional): Whether to perform auto-updating on-initializing. Defaults to True.
            force_download (bool, optional): If set to True, will delete all existing series and download. Defaults to False.
            filter_warnings (bool, optional): Filter the NatualNameWarning generated by PyTables. Defaults to True.
        """
        super(HDFStore, self).__init__(config_file)
        if filter_warnings:
            from tables import NaturalNameWarning
            warnings.filterwarnings("ignore", category=NaturalNameWarning)
        pd.set_option('io.hdf.default_format', 'table')
        self.store = pd.HDFStore(self.config['store']['storage_file'])
        self.mapping: dict = {}
        if 'tengine_mapping' in self.store.root._v_attrs:
            self.mapping = self.store.root._v_attrs.tengine_mapping
        if force_download:
            for (path, subgroups, subkeys) in next(self.store.walk()):
                for subgroup in subgroups:
                    self.store.remove(f'{path}/{subgroup}')
                for subkey in subkeys:
                    self.store.remove(f'{path}/{subkey}')
            self.update()
        elif auto_update:
            self.update()
    
    def add_to_mapping(self, source: str, name: str):
        if source not in self.daemon:
            logger.warning(UserWarning(f'Data Daemon for "{source}" not found, updating will be diabled.'))
        self.mapping[name] = source
        self.store.root._v_attrs.tengine_mapping = self.mapping

    def update(self) -> None:
        """Perform updating, all series defined in mapping but not in datastore will be downloaded.
        Existing series will be check for update 
        """        
        if not self.daemon:
            logger.warning("No module loaded, download/update are disabled", UserWarning)
            return
        keys = self.store.keys()
        download_queue, update_queue = defaultdict(list), defaultdict(list)
        
        for ticker, source in self.mapping.items():
            key = self.create_key(source, ticker)
            if key not in keys:
                download_queue[source].append(ticker)
            else:
                update_queue[source].append(ticker)
        
        for source in download_queue.keys():
            if source in self.daemon:
                if self.daemon[source].BULK_DOWNLOAD:
                    logger.info("Bulk downloading data from {}".format(source))
                    self.download_series_bulk(source, download_queue[source])
                else:
                    tickers = tqdm(download_queue[source])
                    for ticker in tickers:
                        tickers.set_description("Downloading {} from {}".format(ticker, source))
                        self.download_series(source, ticker)
            else:
               logger.warning("No module loaded for source {}, Series {} not downloaded".format(source, ','.join(download_queue[source])), UserWarning)
        for source in update_queue.keys():
            if source in self.daemon:
                if self.daemon[source].BULK_DOWNLOAD:
                    logger.info("Bulk downloading data from {}".format(source))
                    self.download_series_bulk(source, update_queue[source])
                else:
                    tickers = tqdm(update_queue[source])
                    for ticker in tickers:
                        tickers.set_description("Updating {} from {}".format(ticker, source))
                        self.download_series(source, ticker)
            else:
                logger.warning("No module loaded for source {}, Series {} not downloaded".format(source, ','.join(download_queue[source])), UserWarning)

    def download_series(self, source: str, name: str, start=None, end=None, save=True) -> None: 
        tseries: TimeSeries = self.daemon[source].download_series(name, start, end)
        if save:
            key = self.create_key(source, name)
            self.save(tseries, key)
    
    def save(self, tseries: TimeSeries, key: str=None):
        if key is None:
            key = self.create_key(tseries.meta_info['source'], tseries.name)
        self.store.put(key, tseries._df)
        self.store.store.get_storer(key).attrs.tengine_meta_info = tseries.meta_info
        self.store.store.get_storer(key).attrs.tengine_freq = tseries.freq
        self.store.store.get_storer(key).attrs.tengine_name = tseries.name
        self.add_to_mapping(tseries.meta_info['source'], tseries.name)

    def save_bulk(self, tseriess: List[TimeSeries]):
        for tseries in tseriess:
            key = self.create_key(tseries.meta_info['source'], tseries.name)
            self.store.put(key, tseries._df)
            self.store.store.get_storer(key).attrs.tengine_meta_info = tseries.meta_info
            self.store.store.get_storer(key).attrs.tengine_freq = tseries.freq
            self.store.store.get_storer(key).attrs.tengine_name = tseries.name
            self.add_to_mapping(tseries.meta_info['source'], tseries.name)
    
    def download_series_bulk(self, source, tickers, start=None, end=None, save=True):
        raise NotImplementedError

    def get_series(self, name, freq=None, start=None, end=None) -> TimeSeries:
        source = self.mapping.get(name, None)
        if source is None:
            raise_log(KeyError(f"No available data for {name}"))
        key = self.create_key(source, name)
        start, end, query_str = self.create_index_query(start, end)
        try:
            df_raw: pd.DataFrame = self.store.select(key, query_str)
            meta_info: dict = self.store.store.get_storer(key).attrs.tengine_meta_info
            freq_old: str = self.store.store.get_storer(key).attrs.tengine_freq
            name: str = self.store.store.get_storer(key).attrs.tengine_name
        except KeyError:
            raise_log(KeyError("No available data for {} at frequency {} from {}".format(name, freq, source)))

        if freq != freq_old:
            # Resample
            df_raw = df_raw.resample(freq).last().asfreq(fill_value=None)

        return TimeSeries(name, df_raw, freq, meta_info)
    
    @staticmethod
    def create_key(source: str, ticker: str) -> str:
        return (source+'/'+ticker).replace(' ', '_')
    
    @staticmethod
    def create_index_query(start, end) -> Tuple:
        query_str = None
        if start is not None and end is not None:
            start, end = pd.Timestamp(start).to_period('D').to_timestamp(how='e'), pd.Timestamp(end).to_period('D').to_timestamp(how='e')
            query_str = 'index <= end & index >= start'
        elif start is not None:
            start = pd.Timestamp(start)
            query_str = 'index >= start'
        elif end is not None:
            end = pd.Timestamp(end)
            query_str = 'index <= end'
        return start, end, query_str
    
    def close(self):
        self.store.close()

    def __getitem__(self, series_name):
        return self.get_series(series_name)

    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_value, traceback):
        self.close()
